# 在线文本比对

[比较好用的工具](http://www.jq22.com/textDifference)



# json.loads()报错

报错信息：ValueError：Extra data

原因：直接将{},{},{},{}形式的字符串送入json.loads()

解决方法:[{},{},{},{}]形式的字符串送入json.loads()即可



# 动态加载的网页爬取

### [Scrapy框架结合Spynner采集需进行js,ajax动态加载的网页并提取网页信息](http://doc.okbase.net/kevinflynn/archive/163892.html)

### [Scrapy抓取Ajax动态页面](https://www.jianshu.com/p/1e35bcb1cf21)



# Scrapy经验

## [Scrapy各类爬虫集合](https://www.jianshu.com/p/dcd6438ce4c7)

## [Scrapy入门到进阶](https://www.jianshu.com/p/be856bc15afb)

- 包括Scrapy的**中间件**使用
- **解决的问题：**
  1. User agent 过滤
  2. 模糊的JavaScript重定向
  3. 验证码（可用pytesseract模块解决，也可以调用第三方API）
  4. 请求头一致性检验



确实非常强大，**目前的遇到过的爬虫场景都能使用**，有些部分需要自己去定制化。

以前的认知不够，使用很浅

### [Scrapy数据库写入（可用于多个类型的item对象或单个item对象）](https://blog.csdn.net/qq_42630844/article/details/82500419)

### [Scrapy使用mysqldb操作数据库存储数据（存入多个表）](https://blog.csdn.net/sxc1414749109/article/details/79238397)

### [Scrapy插入Mysql数据库(多表)](https://blog.csdn.net/haoyuexihuai/article/details/82846381)

关键在于parse方法中的yield item，parse方法中可以有多处yield item



# Gerapy使用

### [Scrapy项目部署到Gerapy分布式爬虫框架流程](https://blog.csdn.net/qq_38003892/article/details/80427278)(被参考)

### [详细的使用教程，包括用Gerapy来创建可视化scrapy](https://cuiqingcai.com/4959.html)

[Scrapy+Scrapy-redis+Scrapyd+Gerapy 分布式爬虫框架整合](https://www.cnblogs.com/dazhan/p/9605449.html)(目前没有被参考)

更简洁，更实用些，

优点：操作简单，可视化创建、编辑Scrapy项目

缺点：但是缺少日志可视化

# Scrapydweb使用

### [如何通过 Scrapyd + ScrapydWeb 简单高效地部署和监控分布式爬虫项目](http://blog.51cto.com/14090467/2321849?source=drh)

**用起来和Gerapy相比，各有千秋**

优点：日志可视化，操作维度很多；多方面比Gerapy强大

缺点：有些功能冗余

# 数据库报错

## 报错一

mysql数据库建表示要制定utf8，不然会使用默认的latin。

默认的latin，在第三方数据库管理工具中直接执行sql语句insert汉字，不会出现报错和乱码，

**but**默认的latin，在流写入时，比如scrapy中使用pymysql向数据库中insert汉字时，会报错。

```
CREATE TABLE fourMarket
(
    market VARCHAR(30),
    date VARCHAR(30),
    data TEXT,
    flag_id VARCHAR(30),
    response_url VARCHAR(200),
    update_time DATETIME
)ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

## 报错二

字段过长的话，用**TEXT**类型，因为VARCHAR的长度有限制。