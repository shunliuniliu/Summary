# 2018.12.11

## 今日完成进度

- 已完成Anaconda、Git、Pycharm、DataGrip、Sublime Text、Typora等开发与办公软件的安装
- 熟悉python-pptx模块操作ppt，并完成共250+行的2个使用Demo，整理出文档

## 明天任务

- ~~等待南方通帐号激活~~
- ~~安装wind，连接数据库~~
- ~~接收周总的[指数投资]的资料，并完成学习~~



# 2018.12.12

## 今日进度

- 安装Mysql
- 熟悉python操作excel和word的模块，并完成多个使用Demo，整理出文档
- 配置安装PLSQL
- 学习ETF的ppt资料
- 开通wind、南方通
- **接受周总的沪港通、深刚通、陆港通任务**。加上**量化研究任务**，预计两三周内完成
  1. 先爬取港交所的数据到数据库中，
  2. 等wind的代码生成器可用后，把陆港通数据存储到数据库中
  3. 先完成数据采集的任务，再和周总商量比对方案、

## 第一阶段任务

- 完成可视化爬虫系统
- 完成港交所官网数据和wind数据的比对验证

## 明天任务

- ~~把金融大数据处理、fluent python、量化投资这几本书带过来~~

- [~~先爬取港交所的数据到数据库中~~](https://sc.hkex.com.hk/TuniS/www.hkex.com.hk/Mutual-Market/Stock-Connect/Statistics/Historical-Daily?sc_lang=zh-CN#select4=0&select5=0&select3=0&select2=11&select1=11)

- **~~等wind的代码生成器可用后，把陆港通数据存储到数据库中~~**，直接连接wind底层oracle数据库即可，速度更快且没有数据限制。

### 方案（验证可行）

Gerapy、Scrapy、~~查找及借鉴github现有项目~~、~~试一下八爪鱼~~

PLSQL Developer还需要配置python接口，直接连公司买的数据库，没有数据量的限制，wind的python接口会有数据量的限制

# 2018.12.13

## 今日进度

- 确定Gerapy、Scrapy的方案，已确定使用了Gerapy、Scrapy、Scrapyd，还使用了Scrapydweb
- 完成了一个完整的爬虫，总结遇到的各类问题，见文档**[2018.12.13-Gerapy和Scrapyd 部署Scrapy项目-Scrapydweb和Scrapyd 部署Scrapy项目]**
- ~~[安装谷歌浏览器插件SelectorGadge](https://www.jianshu.com/p/3465b700b11f)，简化【选择网页中节点】~~（项目中暂时不需要）可以简化自己写选择器逻辑

## 明天任务

- ~~把金融大数据处理、fluent python、量化投资这几本书带过来~~
- ~~等wind的代码生成器可用后，把陆港通数据存储到数据库中。或者通过PLSQL连接底层数据库~~。直接连接wind底层oracle数据库即可，速度更快其没有数据限制。
- ~~询问周总，两个来源的数据比较哪些点。~~



# 2018.12.14

## 今日进度

- 完成Gerapy、Scrapy港交所官网爬虫的2.0版本，进一步优化了插入数据库的操作。
  1. 沉淀出一个可视化爬虫系统——针对港交所的深港通沪港通的每日数据
  2. 沉淀出一个Oracle和Mysql数据库之间互导数据的脚本工具
- PLSQL读取【陆港通前十大成交活跃股】SHSCTOP10ACTIVESTOCKS的数据，把数据从Oracle导到Mysql中。完成港交所官网数据和wind数据的比对。结论：比对之后，港交所官网上的数据在wind中都有，且是wind数据库的子集。

## 第二阶段任务

目的：

- 分析出香港投资者及内地投资者的投资偏好，与市场影响直接的关系
- 分析与沪深港三地股市的涨跌趋势的关系

执行途径：

- 通过wind寻找【分类】数据，各种类别的信息，比如“持仓”，“陆港通卖空数据”等
- 分析“北上”、“南下”的资金历史走向、趋势变化等，频率包括每月、每周、每日
- 看研报，找找思路
- 事件影响。事件发生日的市场变化，对市场的近期长期的影响

# 2018.12.17

## 第二阶段任务补充：

探索使用DM、ML中的算法，比如关联规则挖掘两地股市的数据关联。

## 今日进度： 

- 阅读研究报告、论文探索思路——整理出[参考资料]、[步骤及算法]、[软件工具]，安装相关的数据分析软件和模块。

- 积累相关概念

## 明天任务：

优先级一：

- 实现至少一篇论文的步骤及算法，验证结论
- 再此基础上，探索下自己的创新思路

优先级二：

- 针对事件驱动，考虑训练下自然语言处理，进行分类打分的预测模型
- 思考下下DM、ML中的回归、分类算法，哪些可以运用。

# 2018.12.18

## 今日进度： 

- 论文[深港联动性分析]的实证完成70% （**后续继续完成**）

## 明天任务：

- ~~完成中期答辩的任务的第一项~~


# 2018.12.19

## 今日进度： 

- [中期答辩任务]完成第二项，代码可以复用与第1、4、5项

- 请教石赟凯关于指数与流通市值等的关系逻辑（**后续查资料，整理成文档**）

## 明天任务：

- **~~存在一个问题：SHSCMembers中存在的都是entry 和 remove信息，并不是每个交易日对应的沪股通的所有成分股，需要自己再做进一步处理找wind经理找对应的数据接口~~** 结论是：wind只能这样提供

- 完成[中期答辩任务]完成第1、4项，注意流通市值的数据表是否正确，找wind经理确认

- ~~找wind经理要第5项对应的数据接口或者数据库表~~

- ~~中期答辩~~


# 2018.12.20

## 今日进度： 

- ~~完成答辩~~

## 明天任务：

- ~~**存在一个问题：SHSCMembers中存在的都是entry 和 remove信息，并不是每个交易日对应的沪股通的所有成分股，需要自己再做进一步处理找wind经理找对应的数据接口**~~ 结论是：wind只能这样提供

- 完成[中期答辩任务]完成第1、4项，注意流通市值的数据表是否正确，找wind经理确认

- ~~找wind经理要第5项对应的数据接口或者数据库表~~



# 2018.12.21

## 第三阶段任务：

### 一、监控陆股通、港股通标的，一共是沪深港三个市场中的标的监控。

1. 包括entry、remove信息
2. 开发爬虫前，先搞清三方面的情况
   - 陆港通标的
     1. 入选和剔出规则
     2. 公布规则
   - 陆港通临时调整的规则
   - 如何公布标的，公布规则
3. 开发爬虫

### 二、先做A股市场的股本监控

前提：如果T日公布股本变动的情况，T+1日就立即生效，进行调整，则去上交所官网取爬取数据，因为wind有延时；如果是T+3日之后才生效调整，则从wind数据库获取数据即可。

1. 先看上交所官网相关公告，先总结，包括但不限于：公告时间规则
2. 监控的数据包括：股本的变动情况，原因等

## 今日进度： 

- ~~梳理任务及方案~~

## 明天任务：

- 


# 2018.12.24

## 今日进度：

- ~~完成[第三阶段任务一]监控陆股通、港股通标的，一共是沪深港三个市场中的标的监控。~~
  1. ~~入选、剔出、公布等规则文件~~
  2. ~~爬虫代码~~
  3. ~~暂时以excel文件保存，还没完成想好应该按照什么形式展示~~ 
- ~~邮件与wind后台沟通数据表~~

## 明天任务：

- ~~完成[第三阶段任务二] A股市场的股本监控~~
- ~~完成邮件与wind后台沟通数据表~~
- ~~MSCI成份股与港股通调整信息整合~~




# 2018.12.25

## 今日进度：

- ~~完成[第三阶段任务一]监控陆股通、港股通标的，一共是沪深港三个市场中的标的监控。~~
  1. ~~入选、剔出、公布等规则文件~~
  2. ~~爬虫代码~~
  3. ~~MSCI成份股与港股通调整信息整合，并按照肖磊哥要求，输出excel~~
- ~~邮件与wind后台沟通数据表，得到准确的数据表信息~~
- ~~A股市场股本变动监控，完成爬虫脚本。与wind后台沟通了数据表~~

## 明天任务：

- ~~A股市场股本变动监控，完成爬虫脚本，与wind后台沟通了数据表。~~ 明天与周总商量具体以哪个为准。

- ~~完成[中期答辩任务]完成第2项，注意：之前遇到的“沪股通名单”问题，利用wind数据表，自己进行计算出：某一交易日的所有有效的沪股通成份股~~

- 完成[中期答辩任务]完成第1、4项，注意流通市值的数据表是否正确


# 2018.12.26

## 今日进度：

- ~~完成[第三阶段任务二]A股市场股本变动监~~
- ~~完成[中期答辩任务]完成第2项~~

## 明天任务：

- 完成[中期答辩任务]完成第4、1、5项，注意流通市值的数据表是否正确


# 2018.12.27

## 今日进度：

- ~~完成[中期答辩任务]完成第4项~~

## 明天任务：

- ~~把[中期答辩任务]完成第4项代码从github上拉下来，在本地进行部署，保证移植的可靠性~~
- ~~中期答辩任务]完成第2项，（1）增加沪深300，要求展示沪深300和中证500；（2）均要增加可视化折线图~~
- ~~完成[中期答辩任务]完成第1、5项，注意流通市值的数据表是否正确~~



# 2018.12.28

## 今日进度：

- ~~中期答辩任务]完成第1项~~
- ~~中期答辩任务]完成第5项，做完预备工作~~

## 明天任务：

- ~~完成中期答辩任务]完成第5项(公司断电，明天无法完成，只能后天和大后天，来公司做完)~~
- ~~看[养老宝-养老金策略，定投相关策略]~~
- ~~搜索Django做网站的project，更新以前的思路。确定一个合适的方案。~~



# 2018.12.29

## 今日进度：

- 发现有新的项目汇总，mark以下，方便以后空闲时候学习下别人的项目

- [32个Python爬虫项目](https://zhuanlan.zhihu.com/p/27938007)

- [70个Python练手项目列表](https://zhuanlan.zhihu.com/p/27931879)

- 指数增强组-展示网站：

  1. 技术方案（多种）：

     - 整体：Vue.js + uWsgi + Nginx + **Django** + ~~MySQL~~  **Oracle**+ Ubuntu [参考1](https://www.cnblogs.com/jieru/p/7144707.html) [参考2](http://www.geerniya.cn/)

       - [ ] 对Vue不太熟悉，建议换成**Angular+Bootstrap**,bootsreap默认样式太单调，用 **[bootswatch**](https://bootswatch.com/)可以提供不同的主题**(推荐尝试)**
       - [ ] 考虑避免以后的麻烦，使用virtualenv**（暂时可以不需要）**
       - [ ] 构建日志服务 **（暂时可以不需要）（[很简单，配置下、引入模块、代码中写logging即可](https://www.cnblogs.com/jieru/p/7144707.html)）**

     - 后端的数据计算：TA-Lib 、pandas、[pyfolio](https://github.com/quantopian/pyfolio)、[empyrical](https://github.com/quantopian/empyrical)  **(手动计算)**

     - 图表展示：**Pyecharts**(官网有在Django使用的示例)，[Plotly](https://github.com/plotly/plotly.py)，[TuChart](https://github.com/Seedarchangel/TuChart)Tushare和Echarts结合，针对中国股市做常见数据的可视化（可以借鉴该项目的开发思路，如何把代码结构写的优雅）[小型app一样](https://github.com/Seedarchangel/TuChart/blob/master/Example_Graphs/En_US.md)

     - git+Pycharm(使用内置的)做版本控制（**在本地搭建git仓库**）

     - [DJANGO CELERY 定时任务](https://www.cnblogs.com/wumingxiaoyao/p/8521285.html)在Django中配置定时任务很有用（**需要定时任务，但是在代码中实现还是Django框架中实现，看具体难度而定**）

     - [基于Django+celery二次开发动态配置定时任务](https://www.cnblogs.com/huangxiaoxue/p/7266253.html),很适用后期需求多的情况

  2. 可能用到的模块：

     - [Json-to-HTML-Table](https://github.com/afshinm/Json-to-HTML-Table)
     - [ HTML-Table-to-JSON](https://github.com/tremblay/HTML-Table-to-JSON)

  3. 代码检查：

     - Pycharm自带的 Inspect Code（代码静态审查），检查出不符合PEP8规范的地方
     - PyChecker模块可以检查出项目中的bug等

  4. 备选方案考虑: [wordpress搭建网站](https://www.jianshu.com/p/e017a2ea7991?utm_source=oschina-app)，但是有个弊端，就是后续在后台整合python的各种小工具时，无法兼容。**（不适用）**

  5. 消息通知，除了利用公司已有的邮件、短信，还可以考虑用微信通知。**（暂不适用）**

  6. 汇报展示：除了ppt，还有网页版展示[**nodeppt**](https://github.com/ksky521/nodeppt)可以考虑(目前见过的最强大方便的网页版presentation工具，没有之一)

## 明天任务：

- ~~完成中期答辩任务]完成第5项(公司断电，明天无法完成，只能后天和大后天，来公司做完)~~
- ~~看[养老宝-养老金策略，定投相关策略]~~
- ~~搜索Django做网站的project，更新以前的思路。确定一个合适的方案。~~



# 2018.12.30

## 今日进度：

- ~~完成中期答辩任务]完成第5项~~

## 明天任务：

- ~~看[**养老宝-养老金策略(重点)**，定投相关策略]~~
- ~~找Django网站的现有的优秀project~~


# 2019.1.1

## 今日进度：

- [Python运维中20个常用的库和模块](https://zhuanlan.zhihu.com/p/52947756)，重点标出
  1. psutil是一个跨平台库。获取系统运行的进程和系统利用率（内存，CPU,磁盘，网络等），主要用于系统监控，分析和系统资源及进程的管理。
  2. difflib：difflib作为Python的标准模块，无需安装，作用是对比文本之间的差异。
  3. filecmp:系统自带，可以实现文件，目录，遍历子目录的差异，对比功能。
  4. **scapy**([http://www.wecdev.org/projects/scapy/](http://link.zhihu.com/?target=http%3A//www.wecdev.org/projects/scapy/))是一个强大的交互式数据包处理程序，它能够对数据包进行伪造或解包，包括发送数据包，包嗅探，应答和反馈等功能。
  5. playbook：一个非常简单的配置管理和多主机部署系统。
- 基金相关概念

## 明天任务：

- 看[**养老宝-养老金策略(重点)**，定投相关策略]
- ~~找Django网站的现有的优秀project~~



# 2019.1.2

# 第四阶段任务：

- 流程自动化工具，定时任务调度平台。[Django自带的用户身份验证](https://docs.djangoproject.com/zh-hans/2.0/topics/auth/)
- 期货基差

## 今日进度：

- ~~熟悉Django，搭建demo~~
- ~~新增A股股本变动比率：changevol除以totalshare~~
- ~~前十大成交活跃股，做降序排列~~
- 查找“任务调度”、“定时任务”、“可视化的调度”、流程自动化工具或平台(Python)
  1. 轻量级-APScheduler：[参考1 ](https://www.jianshu.com/p/ad2c42245906)、[参考2](https://www.cnblogs.com/domestique/p/7814007.html)、[参考3](https://www.cnblogs.com/alexzu/p/8661909.html)、[同一时刻执行多个定时任务](https://zhuanlan.zhihu.com/p/38427932)、[**flask-apscheduler**](https://github.com/viniciuschiele/flask-apscheduler)、
  2. 用python-crontab实现定时任务（django-crontab实现定时任务：安装django-crontab）[参考1](https://blog.csdn.net/python_tty/article/details/51729569)
  3. 重量级-celery-beat（可结合Django）：[参考1](https://www.cnblogs.com/jiangshanwang/p/9146227.html)、[django celery](https://zhuanlan.zhihu.com/p/30742764)
  4. **自动化运维工具Ansible，自带web界面；带有定时任务模块** （用python做运维，这一个工具足够了！！！）
  5. **Github上可借鉴项目，见star**
- ~~先看flask-apscheduler~~

## 明天任务：

- ~~展示网站第一版~~
- ~~定时任务web工具调通一个demo~~
  1. ~~Github上项目~~
  2. ~~自己用schedule写个简单的~~

# 2019.1.3

## 今日进度：

- ~~孙总指派任务：（1）"成份股处罚"(wind、披露易、证监会官网)（2）深圳创新(根据1.体量 2.行业代表性，wind一级行业即可 3.超过50%控股的大股东，排除国资委 。选出的成份股行业的分布尽量均匀)~~
- 查"归因"、“施密特正交"

## 明天任务：

- ~~展示网站第一版~~
- ~~定时任务web工具调通一个demo~~
  1. ~~Github上项目~~
  2. ~~自己用schedule写个简单的~~




# 2019.1.7

## 今日进度：

- 展示网站修正（按崔总要求）
- 任务调度的调研和周总需求，都已搞清楚。申请完服务器后，开始搭建。
- **结论：验证了**
  1. **ansible太大，不适合这次需求**
  2. **Django celery定时任务功能OK，但是重启等功能和界面不符合**
  3. **Django apschedule定时任务功能OK，但是重启等功能和界面不符合**
- 需要在linux搭建今天调研的project

## 明天任务：

- 做出任务调度平台第一版

- 告诉jiashi：talib有导出json格式的方法

  ````
  >>> print(data.export('json'))
  [
    {
      "last_name": "Adams",
      "age": 90,
      "first_name": "John"
    },
    {
      "last_name": "Ford",
      "age": 83,
      "first_name": "Henry"
    }
  ]
  ````



# 2019.1.8

## 今日进度：

- 完成凯宁哥交待的任务
- 搭建服务器环境

## 明天任务：

- 做出任务调度平台第一版

# 2019.1.9

## 今日进度：

- nginx+gunicorn+supervisor+django部署-探索尝试（完成50%）
- CTask项目搭建（error）
- OpenMangosteen搭建（error）
- Django+Xadmin+celery构造定时任务项目（success）

## 明天任务：

- ​

# 2019.1.10

## 今日进度：

- 完成指数增强-展示网站version2，添加很多新功能

参考资料：

1. [bootstrap table和tableExport导出支持中文的Excel和pdf等表格](https://blog.csdn.net/youand_me/article/details/76642434)
2. [bootstrap-table官网](https://bootstrap-table-examples.wenzhixin.net.cn/index.html?view-source#extensions/export.html)

- 完成定时任务平台初步展示界面

## 明天任务：

- ~~在threegrid表格上加上导出下载文件的功能！！！~~
- 完成dev_task项目搭建，和作者蔡青沟通
- 完成定时任务平台的（1）后端逻辑（2）基本任务添加调度



# 2019.1.11

## 今日进度：

- [Ovirt](https://yq.aliyun.com/ziliao/335135)、[Android App 测试 Appium、Robotium、monkey对比](https://blog.csdn.net/dubo_csdn/article/details/81809705)、app测试网课


- 完成threegrid表格上加上导出下载文件的功能，及表格刷新功能
- Dev_task部署成功，但是uwsgi还未和nginx对接成功
- RabbitMQ:15672
- nginx:8070
- uwsgi:3400
- 参考资料：[使用supervisor支持Python3程序](https://www.cnblogs.com/andy-0212/p/9999639.html)

## 明天任务：

- 论文任务
- dev_task跑通

# 2019.1.12

## 今日进度：

- 总结connection reset by peer的可能原因


- 完成【部署Django+Nginx+Gunicorn】，并分析出每一环节报错的原因。

**[部署Django+Nginx+Gunicorn]**

https://www.cnblogs.com/nanrou/p/7026802.html

https://www.cnblogs.com/gaidy/p/9784919.html

```
gunicorn -w 3 -b 127.0.0.1:8080 project.wsgi:application
```

也可以将gunicorn启动配置化

如果gunicorn没有开reload功能，那么在改django代码之后要手动重启gunicorn。

- 【部署Django+Nginx+uwsgi】也成功

[Django 搭建单服务实现多域名访问](https://mp.weixin.qq.com/s/dDIOlTT2BYupgECCf3dS6Q)

[uwsgi使用](https://www.jianshu.com/p/c3b13b5ad3d7)

**目前部署成功的uwsgi.ini文件**

```
[uwsgi]
# 项目目录
chdir = /home/zhangjinzhi/projects/venv_timed_task/dev_task
# 指定项目的application
wsgi-file = %(chdir)/dev_task/wsgi.py
# 指定sock的文件路径
socket=%(chdir)/logs/uwsgi.sock
# 进程个数
workers=1
pidfile=%(chdir)/pid/uwsgi.pid
# 指定IP端口
# nginx负载均衡使用socket,uwsgi启动服务使用http
#socket=192.168.2.200:8000
http=127.0.0.1:3400
# 启用主进程
master=true
# 自动移除unix Socket和pid文件当服务停止的时候
vacuum=true
# 序列化接受的内容，如果可能的话
thunder-lock=true
# 启用线程
enable-threads=true
# 设置自中断时间
harakiri=30
# 设置缓冲
post-buffering=4096
# 设置日志目录
daemonize=%(chdir)/logs/uwsgi.log
```

- django + gunicorn + nginx 关系剖析

对django + gunicorn + nginx 这三兄弟的理解。首先我们知道，我们访问网站，就是去网络上的一台电脑里访问某个路径下的某个文件，那django的作用主要是做（生产）这个文件，拿一家餐馆来讲，我认为django就是这个餐馆的厨师，他负责做菜，当规模很小的时候，比如路边卖鸡蛋饼的大妈，因为客人不多，所以可以自己问客人要什么，然后再自己做，这就是django和自带的runserver所做的事情；那当规模变大了，比如普通餐馆，客人很多，厨师做菜都来不急了，根本没时间去问客人要什么，所以这个时候我们就需要服务员了，服务员去记录客人要什么，然后跟厨房讲，接着从厨房拿菜给客人，而在这里，gunicorn就是这个服务员；当规模更大一些的时候，每分钟都有几百个人（现实中来讲这已经是多到爆炸了吧）要进餐馆吃饭，你在餐馆里安排再多的服务员也不能处理完这么多客人的请求，而且餐馆的空间是有限的，服务员也占空间，多了放不下，所以这个时候怎么办呢，答案是在餐馆门口安排咨客，有序地引导客人进入餐馆，也可以在门口就帮客人点好菜，提高整体效率，Nginx就扮演了咨客这个角色

- **目前部署成功的conf文件**

```
server{
    listen 8070; # 监听的端口
    server_name 106.13.70.248;
    server_name 127.0.0.1;
    server_name your_www;
    #当请求这些server name的时候，nginx才会做反向代理，0.0.0.0是指全部
    location / {
      proxy_pass http://127.0.0.1:3400;
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;
    }
    # location 顾名思义，定位，就是当访问 / 的时候，nginx会将请求转给本地的8080端口，而后面的设置都是一些基本的配置，可以直接用
    location /static {
      alias /home/zhangjinzhi/projects/venv_timed_task/dev_task/static/;
    }
    # 这个就是配置静态文件的地方，要用绝对地址，对应最开始的目录形式，假设project就在/home下面，那么这样配置就可以的了，还有个前提是，你在开发的时候，采取了django的建议，每个app的静态文件都用多了一层app_name的文件夹来包住。
}
```

**或者：（也成功，配置项更少）**

```
server {
    listen 80;
    server_name 106.13.70.248; # 这是HOST机器的外部域名，用地址也行

    location / {
        proxy_pass http://127.0.0.1:3400; # 这里是指向 gunicorn host 的服务地址
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

}
```

原先一直不成功的conf文件

```
        server{
            listen  8070;
            # server_name     106.13.70.248;
            charset utf-8;
            location /static {
                    #alias /opt/dev_task/static/;
                     alias /home/zhangjinzhi/projects/venv_timed_task/dev_task/static/;
            }
            location / {
                    include     uwsgi_params;
                    uwsgi_pass 127.0.0.1:3400;
            }
            # access_log /data/log/nginx/dev_task_access.log;
            # error_log /data/log/nginx/dev_task_error.log;
    }
```



# 2019.1.13

## 今日进度：

**注意：！！！用自己设置的虚拟环境时，配置文件中的command，一定改成对应自己的虚拟环境中的命令！！**（见目前的server端superviosr.conf文件）

## 明天任务：

- **在服务器上搭建OpenMangosteen**

# 2019.1.14

## 今日进度：

- 走通了单个rabbitmq和celery任务的逻辑，但是还没和前端打通

### 积累：

- Celery的任务模块Task中包含异步任务和同步任务：

  1. 异步任务：业务逻辑中被处罚并发往任务队列，**可以做成“事件触发”任务**
  2. 定时任务：同之前思路，不变

- from future import absolute__import 是拒绝隐式引入，因为celery.py和名字和celery的包名冲突，需要使用这条语句让程序正确地运行。

- [爬虫架构|Celery+RabbitMQ快速入门（四）整合版本](https://www.jianshu.com/p/e526b6742384)

  - ```python
    # 使用RabbitMQ作为消息代理
    BROKER_URL='amqp://spider:*****@IP:端口/****' 
    # 把任务结果存在了Redis
    CELERY_RESULT_BACKEND = 'redis://localhost:6379/0' 
    # 任务序列化和反序列化使用JSON方案
    CELERY_TASK_SERIALIZER = 'json' 
    # 读取任务结果使用JSON
    CELERY_RESULT_SERIALIZER = 'json' 
    # 任务过期时间，不建议直接写86400，应该让这样的magic数字表述更明显
    CELERY_TASK_RESULT_EXPIRES = 60 * 60 * 24 
    # 指定接受的内容类型，是个数组，可以写多个
    CELERY_ACCEPT_CONTENT = ['json']
    ```

  - ```python
    from kombu import Queue
    CELERY_QUEUES = ( # 定义任务队列
        Queue('default', routing_key='task.#'), # 路由键以“task.”开头的消息都进default队列
        Queue('web_tasks', routing_key='web.#'), # 路由键以“web.”开头的消息都进web_tasks队列
    )
    
    CELERY_DEFAULT_EXCHANGE = 'tasks' # 默认的交换机名字为tasks
    CELERY_DEFAULT_EXCHANGE_TYPE = 'topic' # 默认的交换类型是topic
    CELERY_DEFAULT_ROUTING_KEY = 'task.default' # 默认的路由键是task.default，这个路由键符合上面的default队列
    
    CELERY_ROUTES = {
        'projq.tasks.add': { # tasks.add的消息会进入web_tasks队列
        'queue': 'web_tasks',
        'routing_key': 'web.add',
        }
    }
    ```

- [使用LinkExtractor提取链接](https://www.jianshu.com/p/7c5d41c61ad2)

- Scrapy本身并不提供JS渲染解析的功能，那么如何通过Scrapy爬取动态网站的数据呢？**(重要!后续会很有用)**

  - 模拟接口去获取需要的数据（一般也推荐这种方式，毕竟这种方式的效率最高），但是很多网站的接口隐藏的很深，或者接口的加密非常复杂，导致无法获取到它们的数据接口，此种方法很可能就行不通。
  - 借助JS内核，将获取到的含有JS脚本的页面交由JS内核去渲染，最后将渲染后生成的HTML返回给Scrapy解析，**Splash是Scrapy官方推荐的JS渲染引擎**，它是使用Webkit开发的轻量级无界面浏览器，提供基于HTML接口的JS渲染服务。（Selenium和phantomJs应该也是可以，可能没有Slpash方便）
  - Python库的scrapy-splash是一个非常好的选择，这里有一系列的实例教程**[使用Splash爬取动态页面](https://www.jianshu.com/p/e54a407c8a0a)**

- eval() 函数用来执行一个字符串表达式，并返回表达式的值。

- Django中locals()用法：locals()可以直接将函数中所有的变量全部传给模板。当然这可能会传递一些多余的参数，有点浪费内存的嫌疑。

  ```python
  return render(request, 'blog_add.html', locals())
  return render_to_response('blog_add.html', locals())
  ```

- #### Django中过滤器

  模板过滤器可以在变量被显示前修改它，过滤器使用管道字符，如下所示：

  ```
  {{ name|lower }}
  ```

  {{ name }} 变量被过滤器 lower 处理后，文档大写转换文本为小写。

  过滤管道可以被* 套接* ，既是说，一个过滤器管道的输出又可以作为下一个管道的输入：

  ```
  {{ my_list|first|upper }}
  ```

  以上实例将第一个元素并将其转化为大写。

  有些过滤器有参数。 过滤器的参数跟随冒号之后并且总是以双引号包含。 例如：

  ```
  {{ bio|truncatewords:"30" }}
  ```

  这个将显示变量 bio 的前30个词。

  其他过滤器：

  - addslashes : 添加反斜杠到任何反斜杠、单引号或者双引号前面。

  - date : 按指定的格式字符串参数格式化 date 或者 datetime 对象，实例：

    ```
    {{ pub_date|date:"F j, Y" }}
    ```

## 明天任务：

- 定时任务-解决报错




# 2019.1.15

## 今日进度：

- 因子-风格-smartbeta--主题-择时

- 指数研究平台

- 事件研究->主题研究

- 实盘选股中：策略和基准，两个表放一起

- - 因子监控-每周更新


  - 风格监控-8个类，每日更新
  -  回测红利：以中证红利做demo

## 待完成：

### 指数增强组-回测信息展示：

回测-红利excel表信息：

- daily-rtn：各个公司研发的指数，比如标普红利机会
- 月度表现：标普红利机会的每月收益等信息
- 年度表现：标普红利机会的每年收益等信息
- 累计表现：从起始日到结束日，各个指数的累计表现
- 每期持仓：指数的每期股票持仓信息，比如中证红利
- 每期行业：指数的每期股票所属行业信息，比如中证红利

SmartBeta网页:

- 行情信息，单基金策略和基准相比，有详情页链接
- smartbeta类别名，这一列新增一个tab，有详情页链接。单个类别内，如红利，内部进行回测对比
  - 回测点进去，展示“回测-红利”excel的累计表现信息
    - 具体内容，**中证红利**每一个选股日的信息。





# 2019.1.16

## 今日进度：

- 使用”tree -L 1 “这个命令，只查看当前第一级的目录和文件使用”tree -L 2 “这个命令，只查看当前第二级的目录和文件使用”tree -L N “这个命令，只查看当前第N级的目录和文件
- 将上述的结果导入到test.txt文件中：tree -L 2 >/var/test.txt



汇总

开始日，结束日，策略总收益，基准总收益，超额总收益，策略年化，基准年化，年华超额，跟踪误差，信息比率，相对最大回撤，回撤起始日，回撤结束日，年华换手率(双)，平均持股数量，

````
'date_of_foundation','last_trading_day','total_strategy_profit_summary','total_benchmark_profit_summary',
                      'total_alpha_profit_summary','annual_strategy_profit_summary','annual_benchmark_profit_summary','annual_alpha_profit_summary','tracking_error_summary',
                      'IR_summary','alpha_maximum_drawdown_summary','start_date_of_maximum_drawdown_summary','end_date_of_maximum_drawdow_summary','annual_turnover_summary','average_hold_num_summary'
                      
                      
{"date_of_foundation":"2016-01-01",
"last_trading_day":"2019-01-01",
"total_strategy_profit_summary":"666",
"total_benchmark_profit_summary":"666",
"total_alpha_profit_summary":"666",
"annual_strategy_profit_summary":"666",
"annual_benchmark_profit_summary":"666",
"annual_alpha_profit_summary":"666",
"tracking_error_summary":"666",
"IR_summary":"666",
"alpha_maximum_drawdown_summary":"666",
"start_date_of_maximum_drawdown_summary":"666",
"end_date_of_maximum_drawdow_summary":"666",
"annual_turnover_summary":"666",
"average_hold_num_summary"}
````

yearly

年份，策略收益，基准收益，超额收益，跟踪误差，信息比率，相对最大回撤，回撤起始日，回撤结束日，换手率(双)，平均持股数量，



# 2019.1.17

## 今日进度：

外部组合跟踪：增强基金跟踪、券商组合跟踪



# 2019.1.18

## 今日进度：

- 策略收益详情页，加上submit功能，在该页面内可以选择“某策略”。
- jiashi需要把导航页中的每个策略详情页连接，设置为不同的详情链接，不能使用现在的统一的命名。
  - 各个详情链接不同，但是有**相同的url+不同的参数**，后端判断参数，然后取到不同json。最后在一个页面内进行渲染，该页面内也提供submit，提交表单，得到不同策略的详情页。



- 表格也可以采用动态渲染，columns动态传入即可。



````
'year_yearly','strategy_profit_yearly','benchmark_profit_yearly','alpha_profit_yearly','tracking_error_yearly',
                      'IR_yearly','alpha_maximum_drawdown_yearly','start_date_of_maximum_drawdown_yearly','end_date_of_maximum_drawdow_yearly','annual_dual_turnover_yearly','average_hold_num_yearly'

{"year_yearly":"23",
"strategy_profit_yearly":"23",
"benchmark_profit_yearly":"23",
"alpha_profit_yearly":"23",
"tracking_error_yearly":"23",
"IR_yearly":"23",
"alpha_maximum_drawdown_yearly":"23",
"start_date_of_maximum_drawdown_yearly":"23",
"end_date_of_maximum_drawdow_yearly":"23",
"annual_dual_turnover_yearly":"23",
"average_hold_num_yearly":"23"}

````



增强基金跟踪表格：

基金代码、基金简称、最新规模(亿)、截止日期、最近日收益、今年累计收益、今年累计超额、今年信息比率、今年最大相对回撤



# 2019.1.19

## 今日进度：

## 以下了解到的新知识，可以在碰到需求时，权衡对比后进行取舍

### web技术开发：1、网站  2、桌面应用 3、虚拟桌面(利用web操作系统)

- web.py知名的python轻量级web框架，比flask还轻，小项目可以一用
- web技术可以开发桌面应用程序（如hteos框架，适用于任何后台技术平台，模块化）。桌面 app 或者 web app
- Web操作系统：比如chrome的web操作系统，**http://yun.dajiqq.com** **WebQQ增强版**也很像web操作系统（切换系统真实桌面和WebQQ的虚拟桌面。感觉上就像你的操作系统被扩展了，可以使电脑拥有多个云端的桌面。这些WebQQ的虚拟桌面其实与网页版WebQQ的桌面是一样的，只不过在增强版里它们能全屏显示，并且可以与系统的桌面切换，让人感觉跟真实的操作系统融为一体了，云端桌面的的内容其实和网页版WebQQ是完全一致的，）



## 定时任务平台-新思路：（关注业界实用技术和工具很重要）

1. jenkins可以添加监控一些定时执行的任务

2. Django+Ansible+PlayBook
3. airflow：DAG神器，自带任务调度



量化平台：

掘金量化可以支持机构发产品，多家合作券商实盘。掘金客户端支持本地编译运行，支持本地实盘，支持多语言

同花顺MindGo 能链接任意实盘账户





监控

数据提取:

每一个需求的提取数据

**部门规模**

**单个基金**

**规模排名**：（按行业的排名）多个选择框，包含多个业务需求

结果浮窗



外部组合：



近一日到近三月 改成超额



信息比率，跟踪误差



红哥——详情页



# 2019.1.21

## 今日进度：

### 非常全面的django后台管理模版，所有需要的组件和功能都有

https://colorlib.com/polygon/metis/

https://adminlte.io/themes/AdminLTE/pages/forms/advanced.html



## 新任务

今天和昨天的数据表校对

参数清单、估值表、指数权重表



1. 生成调仓日有bug
2. 最近调仓日，国证、深圳成指指数生效日前一天的调仓（深市）



## 明天任务：

- ~~数据提取功能页，增加新的展示，询问leijie~~
- 红哥-详情页
- 蕾姐-详细报告页，找凯宁哥（在单个基金一栏中增加一个模态窗口作为详情页，展示excel表中的详细内容）





# 2019.1.24

## 明日任务：

- 指数研究平台:(待完成部分)
  1. ~~[外部组合跟踪]导航页面和[外部组合跟踪]详情页面中的增强基金跟踪-前端部分~~，
     - 对应的**后端代码**
  2. [Smartbeta]详情页面，已中证红利作为例子，完成前端和后端代码。
  3. [数据提取]的“单个基金”中新增模态窗口，作为详情页，展示详细图表。需要完成前端和后台代码。
  4. ~~验证与jiashi的交互逻辑~~
- 定时任务平台:(待完成部分)
  - 前端:
    - (1)任务结果展示页面、手动重启功能 
  - 后端:
    - (1)[任务执行功能]的代码
- PCF校验：(待完成)
  - (1)修复[PCF校验]程序bug





```
ab_CN_dict = {'SZ50_INDEX':'上证50','HS300_INDEX':'沪深300','ZZ500_INDEX':'中证500'
              ,'CYBZ_INDEX':'创业板指','ZZQZ_INDEX':'中证全指','XKZS_INDEX':'小康指数','ZZ1000_INDEX':'中证1000','ZZ800_INDEX':'中证800'}
```



# 2019.1.25-27

## 今日进度：

1. **jenkins可以添加监控一些定时执行的任务，尝试。完成**
2. 发现还有**teamcity**等持续集成工具都可以做定时任务和监控
3. **python将markdown转成html5**展示 http://isnowfy.github.io/pydown/
4. [**Jumpserver是全球首款完全开源的堡垒机，是符合 4A 的专业运维审计系统**](https://github.com/jumpserver/jumpserver) （非常强大，运维平台，类IDE文件上传、terminal）
5. **airflow！！！可以结合celery、flower等一起用**





正确的uwsgi ini文件配置

```
[uwsgi]
# 项目目录
chdir=/opt/dev_task/
# 指定项目的application
wsgi-file = %(chdir)/dev_task/wsgi.py
# 指定sock的文件路径
socket=%(chdir)/logs/uwsgi.sock
# 进程个数
workers=1
pidfile=%(chdir)/pid/uwsgi.pid
# 指定IP端口
# nginx负载均衡使用socket,uwsgi启动服务使用http
#socket=192.168.2.200:8000
http=127.0.0.1:3400
# 启用主进程
master=true
# 平滑地重启
reload-mercy = 10
# 自动移除unix Socket和pid文件当服务停止的时候
vacuum=true
# 序列化接受的内容，如果可能的话
thunder-lock=true
# 启用线程
enable-threads=true
# 设置自中断时间
harakiri=30
# 设置缓冲
post-buffering=4096
# 设置日志目录
daemonize=%(chdir)/logs/uwsgi.log
```

改成这个配置也可以。如果用socket的话，会报错invalid request block size: 21573 (max 4096)...skip

```
[uwsgi]

http=127.0.0.1:3400

;http=0.0.0.0:8070

chdir=/opt/dev_task/

module=dev_task.wsgi

processes=4

threads=2

master=True

reload-mercy = 10

vacuum=True

pidfile=/opt/dev_task/pid/uwsgi.pid

;daemonize=/opt/dev_task/logs/uwsgi.log
```

原因剖析：

`socket` option intended to be used with some third-party router (nginx for instance), while when `http` option is set uwsgi can accept incoming HTTP requests and route them by itself.



在已经安装了MySQLdb、mysqlclient的前提下，如果仍然报错MySQLdb相关的，在`dev-task/dev-task/__init__.py`中添加

```
import pymysql
pymysql.install_as_MySQLdb()
```









**项目手动启动：**

cd到/opt/dev_task目录下，然后执行下面命令

```
celery -A dev_task beat --pidfile=/opt/dev_task/pid/beat.pid --loglevel=INFO -S django

celery -A dev_task worker --pidfile=/opt/dev_task/pid/worker.pid --loglevel=INFO -Ofair

uwsgi --ini uwsgi.ini 

flower -A dev_task  --port=5555  会有报错信息，但是不影响使用


```

通过和作者的交流，将flower启动添加到了supervisord.conf文件中

**一共有三处修改：**

- **mytag.py中增加isinstance类型判断**

- **views中的”任务结果类“，增加数组index范围判断，防止数组越界**
- **supervisord.conf中增加【启动flower】**  **（支持项目自动启动）**



调试技巧：

1. 用 manage.py runserver  去调试 ，把debug 打开 
2. **开启django  log（明天的任务）**



Ubuntu添加新用户https://blog.csdn.net/tennysonsky/article/details/78972295



基于Boostrap, Django的admin管理界面https://adminlte.io/

## 明天任务：

- 把工具代码整理，发给yun kai
- 完成产品方案
- 网站后台脚本，找gang chen
- 定时任务，重新部署，试验下。后续尝试docker





# 2019.1.28

## 今日进度：

- 产品原型图

## 明天任务：

- **校验程序bug排错**

- ~~把工具代码整理，发给yun kai~~
- 网站后台脚本，找gang chen
- 定时任务，重新部署，试验下。后续尝试docker



# 2019.1.30

## 今日进度：

### PCF校验程序：

坑点：

- 代码中除了sys.reload，print，还有filter会引起python2.7和python3之间差异。filter在python2.7中是返回列表，在python3中是返回一个迭代器。所以用assert取判断len(迭代器)=1会报错。

- 虽然两套源码一样，但是错误复现不一样，怀疑是因为PyInstaller在打包时参数不同引起的差异。其中一个报错信息显示：找不到上一个作者的wind dll路径。

- **在代码里面尽量不要用import，能from.....import....就尽量用这个，因为如果是import的话，在打包的时候，会将整个包都打包到exe里面，没有意义的增大了工具的大小！还会导致exe文件打开过慢。**

- PyInstaller打包得到的exe文件，还会依赖外部文件，需要设置好外部依赖文件的路径。

  （用法很多，需要详细查阅。）

### [easyicon](https://www.easyicon.net/)免费的图标库

## 明天任务：

- **校验程序bug排错**，需要将python2.7的环境设置好，不能用python3的环境
- 定时任务，重新部署，试验下。后续尝试docker

# 2019.1.31

## 今日进度：

由于不知道pcf校验程序的原作者的开发环境和配置，采用anaconda较为保险省心



### PCF校验程序：

#### 一、报错类型: 关于PyQt的plugin报错

- 自己在python2.7中手动安装各个依赖模块，手动指定版本

#### 解决方法:

- anaconda2可以直接装到anaconda3的env虚拟环境中，实现anaconda2和3共存
- 也可以将anaconda2单独装在一个目录下面，手动在Pycharm中添加python解释器，或者手动输入command lines执行

- 自己一个个安装PyQt依赖的模块，由于版本问题报错多，耗时耗力，anaconda省心

#### 二、报错类型: No module named WindPy报错

- 前提：当本机装有anaconda2、anaconda3等多个时，且并不是所有anaconda都写入注册表。
- 在wind中点击修复Python接口，修改界面显示完成

#### 解决方法:

- 在wind中点击修复Python接口，修改界面显示完成。此时要在修复界面最后一栏点击**配置详情**，查看路径

- 如果没有当前所使用的anaconda2的路径，手动添加路径，并再次点击修复python接口。

  （如果不能自动修复成功，只能手动安装修复插件，目前还没出现过不能自动修复）

#### 三、报错类型：Timestamp object has no to_datetime attribute

- 报错位置多处：比如Val_in.index[0].to_datetime()

#### 解决方法:

将代码中的to_datetime改成to_pydatetime

```
查询官方说明，有to_datetme64和to_pydatetime两个方法，后者是可以将timestamp类型object转换为datetime中的类型

to_pydatetime	Convert a Timestamp object to a native Python datetime object.
to_datetime64	Returns a numpy.datetime64 object with ‘ns’ precision
```

#### 四、对比检查了一堆，发现不是编码问题。但是很多代码操作会报warning

所幸可以有信心确定是代码的业务逻辑问题！！！

#### 五、结合业务逻辑，排查出是因为除了check_package_SH.py文件外，其他文件中均缺少了传入transfer(GUI上的调仓标志)参数

原本为：

```
fundmental_data[u'名称一致性(昨晚-今晚权重导入)']=fundmental_data[u'证券代码'].apply(lambda x : fundmental_data.set_index(u'证券代码').loc[x,u'证券名称']==weight_pre.set_index(u'成分券代码\nConstituent Code').loc[x,u'成分券名称\nConstituent Name']).apply(lambda x : 'OK' if True else u'错误')
fundmental_data[u'自由流通量(昨晚-今晚权重导入)']=fundmental_data[u'证券代码'].apply(lambda x : float(weight_tonight.set_index(u'成分券代码\nConstituent Code').loc[x,u'计算用股本(股)\nShares in Index(share)'])-\
   
```

改为：

```
if transfer == 0:
    fundmental_data[u'名称一致性(昨晚-今晚权重导入)']=fundmental_data[u'证券代码'].apply(lambda x : fundmental_data.set_index(u'证券代码').loc[x,u'证券名称']==weight_pre.set_index(u'成分券代码\nConstituent Code').loc[x,u'成分券名称\nConstituent Name']).apply(lambda x : 'OK' if True else u'错误')
    fundmental_data[u'自由流通量(昨晚-今晚权重导入)']=fundmental_data[u'证券代码'].apply(lambda x : float(weight_tonight.set_index(u'成分券代码\nConstituent Code').loc[x,u'计算用股本(股)\nShares in Index(share)'])-\
   
```



**验证数据：**

创业板EF  调仓日数据和非调仓日数据

300ETF    调仓日数据和非调仓日数据

深成ETF   调仓日数据和非调仓日数据

MSCI基金 调仓日数据和非调仓日数据

H股ETF     调仓日数据和非调仓日数据



Config.xslx配置文件

(已验证数据，在下面加粗)

| 基金代码 | 基金简称     | 市场类型（0：上海跨、单市场，1：深圳跨、单市场，2：上海跨境，3：深圳跨境） | 有无隐藏股 | 0股阈值 |
| -------- | ------------ | ------------------------------------------------------------ | ---------- | ------- |
| 159903   | **深成ETF**  | **1**                                                        | 0          | 0       |
| 159925   | **300ETF**   | **4**                                                        | 0          | 0       |
| 159948   | **创业板EF** | **1**                                                        | 0          | 0       |
| 510160   | 小康ETF      | 0                                                            | 0          | 0       |
| 510290   | 380ETF       | 0                                                            | 0          | 0       |
| 510500   | 500ETF       | 0                                                            | 0          | 0       |
| 512100   | 1000ETF      | 0                                                            | 1          | 38      |
| 512160   | **MSCI基金** | **0**                                                        | 0          | 0       |
| 512200   | 房地产       | 0                                                            | 0          | 0       |
| 512300   | 500医药      | 0                                                            | 0          | 0       |
| 512310   | 500工业      | 0                                                            | 0          | 0       |
| 512330   | 500信息      | 0                                                            | 0          | 0       |
| 512340   | 500原料      | 0                                                            | 0          | 0       |
| 512400   | 有色金属     | 0                                                            | 0          | 0       |
| 512700   | 银行基金     | 0                                                            | 0          | 0       |
| 512900   | 证券基金     | 0                                                            | 0          | 0       |
| 513600   | 恒指ETF      | 2                                                            | 0          | 0       |
| 159954   | **H股ETF**   | **3**                                                        | 0          | 0       |

## 明天任务：

- 用PyInstaller打包



# 2019.1.31

## 今日进度：



### 用PyInstaller打包PCF校验程序：

#### 一、错误： cannot find existing PyQt5 pluign directories

- 用**pyinstaller -F GUI.py** 或者pyinstaller GUI.spec

```
 Cannot find existing PyQt5 pluign directories
 Paths checked：C:/Users/xxx/xxx/xxx/xxx/plugins
```

#### 解决办法一（已采用，验证可行）：

根据Paths checked后面的路径建立文件夹，把Anaconda下的qt文件夹里的plugins文件夹下的所有文件复制到新建的文件夹里，我的电脑上对应的位置是：D:\Anaconda\pkgs\qt-5.6.2-vc14_6\Library\plugins，再重新打包即可成功。

#### 解决方法二（未验证可行性）

pyinstaller打包使用pyqt5模块的时候，在win平台下，由于pyinstaller无法准确获取QT动态库文件路径，会报错导致无法打开运行程序，并提示错误信息pyinstaller failed to execute script pyi_rth_qt5plugins此时我们需要在打包的时候直接告诉pyinstaller到哪里去找，这个路径分隔符需要是unix形式：

```
pyinstaller --paths C:/****/Python/Python35-32/Lib/site-packages/PyQt5/Qt/bin -F -w ****.py
```

#### 结论：

1.解决掉上面错误后，执行**pyinstaller -F GUI.py** 命令即可，在当前目录下的dist文件夹下会生成一个exe程序。

2.由于该GUI.exe依赖外部文件，所以将exe程序放在GUI.py同目录下。理论上所有py文件可以删除，只需要依赖的一些文件和文件夹即可。



# 2019.2.11

## 今日进度：

- 13个项目中所有程序类项目，均添加README说明文档。
- 对定时任务平台和指数研究平台，添加架构图、架构原理说明，关键部分讲解

## 明天任务：

- 在公司服务器上部署指数研究平台



# 2019.2.12

## 今日进度：

### 凯宁哥本地Oracle相关错误

- 帮助凯宁哥排查python3连接oracle报错，对相关报错及原理有了进一步了解

  - 报错1：DatabaseError: DPI-1047: 64-bit Oracle Client library cannot be loaded: "D:\oracle\product\10.2.0\client_1\bin\oci.dll is not the correct architecture".

    1. 导致这个错误的原因是：服务器oracle版本和客户端cx_oracle客户端版本不一致引起的，所以通过下面命令询oracle版本。

       ```python
       select * from v$version
       ```

    2. 凯宁哥的PC上的plsql客户端和instanceclient都是32位，但是python3是64位。

       - 需要将三者的位数保持一致

    3. 故新装64位的plsql客户端和instanceclient，原有32位的可以不删除，但是需要将“环境变量”换成新的路径。

  - 报错2：实际上没有报错，但是新的64位的plsql客户端中TNSname文件路径显示是老的32位instanceclient路径。

    1. 理论上，在plsql客户端中设置好Oracle Home和OCI Library路径后，能够自动找到Network\Admin路径下的tnsnames.ora文件
    2. 分析原因后，推断是因为windows系统中的相关注册表中有老的32位instanceclient中的信息，而导致的
    3. 验证自己的分析推断：将老的32位的instanceclient文件夹改名字（凯宁哥的命名是是oracle/xxx/xxx），相当于让注册表找不到了该文件夹。
    4. 重启plsql客户端，点击Help中的Support Info，显示TNSname文件路径已经改为了新的64位instanceclient中的Network\Admin路径下的tnsnames.ora文件
    5. 到此验证了推断。解决问题

### 嘉时代码在本地PC上正常，在部门ubuntu服务器上报错

- 调用pandas的read_sql接口，可以很方便的将sql表中数据读出来得到DataFrame格式。而不需要自己用cursor读取后，解析创建为DataFrame格式。

- [python 连接 Oracle 乱码问题（cx_Oracle）](https://www.cnblogs.com/chenjianhong/p/4144399.html)

  ```
  用python连接Oracle是总是乱码，最后发现时oracle客户端的字符编码设置不对。
  
  编写的python脚本中需要加入如下几句：
  
  import os
  os.environ['NLS_LANG'] = 'SIMPLIFIED CHINESE_CHINA.UTF8'
  
  这样可以保证select出来的中文显示没有问题。
  
  要能够正常的insert和update中文，还需要指定python源文件的字符集密码和oracle一致。
  ```

- python连接oracle报错没有cursor句柄

  - **错误原因是：服务器上没有配置FDMC**
  - 将` wind_connect_info = 'jrgc/password_1234@FMDC'`修改为'`wind_connect_info = 'jrgc/password_1234@10.81.3.115:1532/fmdcsrv`



## 明天任务：

- 数据提取页，重新写界面

# 2019.2.13

## 今日进度：

### 港琛代码报错排查

- 报错信息：type object datetime has no attribute time

- 原因：脚本中import WindPy，同时import time

  ```
  如下顺序：
  import time
  from WindPy import *
  
  t0=time.time()
  ```

  查询Windpy中的代码发现：`from datetime import datetime,date,time,timedelta`

  其中的time和`import time`名字冲突，第一行的import time被覆盖，导致`t0=time.time()`实际上是调用的datetime中的time，所以会报错。

- 解决方法：

  1. 方法一：调换顺序：

     ```
     from WindPy import *
     import time
     
     t0=time.time()
     ```

     后一个time将dateime中的time给覆盖了

  2. 方法二：直接使用datetime中的time或者datetime来计算时间，避开该问题



### 嘉时代码报错排查

- 错误情况：

  - 读取不到新增策略，只能读取到TF-test策略

  - 解决方法：

    ```
    main_back_test.py  中  改成
    strategy_name_list = all_holding_df.S_NAME.unique().tolist()#['TF_test']    #策略名称列表
    
    adjust_holding.py  中 改成
    strategy_all_holding = select_df.copy()
    ```

- 报错信息：

  - KeyError：0。原因：想当然用 [0] 以为取了dataframe的第一行 但是其实在slice之后 index不是从0开始了。之前数据库只有一个策略 所以也调不出这个bug

  - 解决方法：所有类似bug，均改成.iloc[0]

    ```
    benchmark = index_adjust_holding.index_dict[select_df["S_BENCHMARK"].iloc[0]]
    ```

- 错误情况：

  - 生成的json文件存储位置错误。原因是：在本地PC开发时采用的是windows的路径

  - 解决方法：

    ```
    所有涉及文件存储的地方，手动改成linux的路径。
    
    最佳实践是采用os、sys模块，来实现兼容性
    ```



### 发现一个超级强大的file manager，类似于web虚拟桌面

#### [elFinder*file manager for web*](https://studio-42.github.io/elFinder/)

#### [elFinder](https://studio-42.github.io/elFinder/)





### 发现pandas中的dataframe和series有plot方法，可以直接画表格或者line、bar等图!!!!!



